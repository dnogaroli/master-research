{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "import spacy\n",
    "import numpy as np\n",
    "import nltk\n",
    "import string\n",
    "import time\n",
    "from nltk.tokenize import RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spaCy Version: 3.0.6\n",
      "Wall time: 1min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "nlp = spacy.load(\"pt_core_news_lg\", disable=['parser','ner','pos'])\n",
    "print('spaCy Version: %s' % (spacy.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of stop words: 416\n"
     ]
    }
   ],
   "source": [
    "# we'll remove the stopwords in Portuguese using Spacy\n",
    "spacy_stopwords = nlp.Defaults.stop_words\n",
    "print('Number of stop words: %d' % len(spacy_stopwords))\n",
    "#print('Spacy stop words: %s' % spacy_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing words from the stop words list\n",
    "nlp.Defaults.stop_words -= {'direita', 'maiorias', 'maioria', 'grupo', 'meio', 'posição', 'apoio'}\n",
    "\n",
    "# and adding new stop words, different verbs conjugations and pronoms\n",
    "nlp.Defaults.stop_words |= {'há', 'havemos', 'havia', 'houve', 'houvemos', 'houveram', 'hemos',\n",
    "                            'houvera', 'houvéramos', 'houvessem', 'houvesse', 'houvéssemos', 'heis'\n",
    "                            'hão', 'haveis', 'haja', 'hajamos', 'hajam', 'hoje', 'semana', 'dia', \n",
    "                            'dias', 'anos', 'ano', 'eram', 'seja', 'será', 'sendo', 'sido', \n",
    "                            'seremos', 'serão', 'sejam', 'seríamos', 'seriam', 'estamos', \n",
    "                            'haver', 'houver', 'haverá', 'apesar', 'entanto', 'aliás', 'enfim',\n",
    "                            'tinha', 'tínhamos', 'tinham', 'tivera', 'tivéramos', 'tenha', \n",
    "                            'tenhamos', 'tenham', 'tivesse', 'tivéssemos', 'tivessem', 'eis',\n",
    "                            'tiver', 'tivermos', 'tiverem', 'terei', 'terá', 'teremos', 'tendo',\n",
    "                            'terão', 'teria', 'teríamos', 'teriam', 'uso', 'fato', 'etc', 'nome',\n",
    "                            'lo', 'la', 'los', 'las', 'lha', 'lho', 'lhas', 'lhos', 'lhes', 'me', \n",
    "                            'venho', 'venha', 'veio', 'gostaria', 'deles', 'delas', 'acima',\n",
    "                            'mim', 'senhor', 'senhora', 'senhoras', 'senhores', 'dada', 'li',\n",
    "                            'falando', 'falo', 'falou', 'falei', 'digo', 'dizia', 'dizendo',\n",
    "                            'dr', 'drs', 'dra', 'sr', 'sra', 'srs', 'sras', 'exa', 'exas', \n",
    "                            'vamos', 'outro', 'outros', 'quase', 'muita', 'muitas', 'durante', \n",
    "                            'caso', 'disse', 'aparte', 'dessas', 'desses', 'vou', 'várias', \n",
    "                            'mesma', 'posso', 'possa', 'fizeram', 'faremos', 'fiz', 'farei', \n",
    "                            'fazendo', 'feitas', 'àquela', 'dela', 'dele', 'mesmos', 'horas',\n",
    "                            'ocupo', 'ocupa', 'ocupar', 'ocupei', 'subo', 'assomo', 'assumo', \n",
    "                            'volto', 'volta', 'ocupamos', 'deixe', 'deixar', 'deixo', 'nobre',\n",
    "                            'nessas', 'nesses', 'devemos', 'podemos', 'pudesse', 'possamos', 'possam', \n",
    "                            'possui', 'poderia', 'poderão', 'serem', 'fosse', 'ficar', 'fica', \n",
    "                            'ficou', 'fico' 'deu', 'dando', 'queremos', 'queria', 'feito', 'feita', \n",
    "                            'feitas', 'feitos', 'sabemos', 'sabem', 'sabes', 'apesar', 'senão', \n",
    "                            'termos', 'deram', 'estavam', 'questões', 'coisas', 'tantas', \n",
    "                            'tantos', 'daqui', 'algum', 'alguém', 'passar', 'passo', 'modo', \n",
    "                            'tomou', 'posse', 'vice', 'agradeço', 'parabéns', 'sair',\n",
    "                            'maneira', 'seguinte', 'seguida', 'seguido', 'acho', 'vimos', 'vi',\n",
    "                            'vejo', 'viu', 'vejo', 'vê', 'deu', 'dê', 'dava', 'pôs', 'pro', 'pra',\n",
    "                            'traz', 'trazer', 'chegar', 'chegou', 'está', 'esta', 'fala', 'vista',\n",
    "                            'ir', 'iriam', 'iam', 'indo','entretanto', 'todavia', 'existir', \n",
    "                            'estava', 'existem', 'existe', 'precisam', 'precisa', 'diziam', 'dizer',\n",
    "                            'dizíamos', 'falar', 'querer', 'voltarem', 'começarem', 'cerca',\n",
    "                            'daí', 'gente', 'tido', 'inicialmente', 'prazer', 'prezado', 'prezados',\n",
    "                            'ninguém', 'hora', 'minutos', 'trouxe', 'saudar', 'ida', 'saudá',\n",
    "                            'recentemente', 'usei', 'chega', 'cabe', 'minutos', 'peça', 'peço',\n",
    "                            'trouxe', 'dentre'\n",
    "                            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of stop words with new inputs: 661\n"
     ]
    }
   ],
   "source": [
    "# checking new stop words list value\n",
    "print('Number of stop words with new inputs: %d' % len(spacy_stopwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import df\n",
    "df = pd.read_csv('amazon_clean_discourses.tsv', sep='\\t', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>session</th>\n",
       "      <th>phase</th>\n",
       "      <th>discourse_link</th>\n",
       "      <th>speaker</th>\n",
       "      <th>party</th>\n",
       "      <th>coalition</th>\n",
       "      <th>state</th>\n",
       "      <th>region</th>\n",
       "      <th>original_discourse</th>\n",
       "      <th>clean_discourse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-01-11</td>\n",
       "      <td>195.2.51.O</td>\n",
       "      <td>short address</td>\n",
       "      <td>https://www.camara.leg.br/internet/SitaqWeb/Te...</td>\n",
       "      <td>nilton capixaba</td>\n",
       "      <td>ptb</td>\n",
       "      <td>opposition</td>\n",
       "      <td>ro</td>\n",
       "      <td>north</td>\n",
       "      <td>O SR. NILTON CAPIXABA (PTB-RO. Pronuncia o seg...</td>\n",
       "      <td>Sr. Presidente, Sras. e Srs. Deputados, na sem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-01-11</td>\n",
       "      <td>195.2.51.O</td>\n",
       "      <td>parliamentarian communications</td>\n",
       "      <td>https://www.camara.leg.br/internet/SitaqWeb/Te...</td>\n",
       "      <td>sérgio novais</td>\n",
       "      <td>psb</td>\n",
       "      <td>opposition</td>\n",
       "      <td>ce</td>\n",
       "      <td>northeast</td>\n",
       "      <td>O SR. SÉRGIO NOVAIS (Bloco/PSB-CE. Como Líder....</td>\n",
       "      <td>Sr. Presidente, Sras. e Srs. Deputados, prime...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-01-11</td>\n",
       "      <td>195.2.51.O</td>\n",
       "      <td>short address</td>\n",
       "      <td>https://www.camara.leg.br/internet/SitaqWeb/Te...</td>\n",
       "      <td>marcos afonso</td>\n",
       "      <td>pt</td>\n",
       "      <td>opposition</td>\n",
       "      <td>ac</td>\n",
       "      <td>north</td>\n",
       "      <td>O SR. MARCOS AFONSO (PT-AC. Pronuncia o seguin...</td>\n",
       "      <td>Sr. Presidente, Sras. e Srs. Deputados, venho...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date     session                           phase  \\\n",
       "0  2000-01-11  195.2.51.O                   short address   \n",
       "1  2000-01-11  195.2.51.O  parliamentarian communications   \n",
       "2  2000-01-11  195.2.51.O                   short address   \n",
       "\n",
       "                                      discourse_link          speaker party  \\\n",
       "0  https://www.camara.leg.br/internet/SitaqWeb/Te...  nilton capixaba   ptb   \n",
       "1  https://www.camara.leg.br/internet/SitaqWeb/Te...    sérgio novais   psb   \n",
       "2  https://www.camara.leg.br/internet/SitaqWeb/Te...    marcos afonso    pt   \n",
       "\n",
       "    coalition state     region  \\\n",
       "0  opposition    ro      north   \n",
       "1  opposition    ce  northeast   \n",
       "2  opposition    ac      north   \n",
       "\n",
       "                                  original_discourse  \\\n",
       "0  O SR. NILTON CAPIXABA (PTB-RO. Pronuncia o seg...   \n",
       "1  O SR. SÉRGIO NOVAIS (Bloco/PSB-CE. Como Líder....   \n",
       "2  O SR. MARCOS AFONSO (PT-AC. Pronuncia o seguin...   \n",
       "\n",
       "                                     clean_discourse  \n",
       "0  Sr. Presidente, Sras. e Srs. Deputados, na sem...  \n",
       "1   Sr. Presidente, Sras. e Srs. Deputados, prime...  \n",
       "2   Sr. Presidente, Sras. e Srs. Deputados, venho...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting it to lowercase\n",
    "df[\"tokenized\"] = df[\"clean_discourse\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing punctuation\n",
    "df[\"tokenized\"] = df[\"tokenized\"].apply(lambda x: \" \".join(tokenizer.tokenize(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing numbers\n",
    "df[\"tokenized\"] = df[\"tokenized\"].str.replace('\\d+', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing characters that are not letters or numbers\n",
    "df[\"tokenized\"] = df[\"tokenized\"].str.replace('[#,@,&,º,ª]','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove words less than two char that might be noiseness\n",
    "df[\"tokenized\"] = df['tokenized'].str.findall('\\w{3,}').str.join(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    \"\"\"custom function to remove the stopwords\"\"\"\n",
    "    return \" \".join([word for word in str(text).split() if word not in spacy_stopwords])\n",
    "\n",
    "# removing stopwords\n",
    "df[\"tokenized\"] = df[\"tokenized\"].apply(lambda text: remove_stopwords(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing other frequent words that cause noiseness to our data\n",
    "freq_words = {'presidente', 'presidenta', 'deputado', 'deputados', 'deputada', \n",
    "              'deputadas', 'parlamentares', 'parlamentar', 'colegas', 'colega'\n",
    "              'senador', 'senadora', 'senadores', 'senadoras', 'casa', 'feira', 'nº', 'ª', \n",
    "              'principalmente', 'pronunciamento', 'solicito', 'olá', 'precisamos', \n",
    "              'realmente', 'sobretudo', 'aparte', 'caros', 'importante', \n",
    "              'importantes', 'igualmente', 'perante', 'praticamente', \n",
    "              'especificamente', 'inicialmexnte', 'infelizmente', 'especialmente',\n",
    "              'particularmente', 'exmo', 'exmos', 'querido', 'querida', 'queridos', \n",
    "              'queridas', 'companheiro', 'companheiros', 'companheira', 'companheiras',\n",
    "              'registrado', 'registrada', 'registro', 'brasileira', 'brasileiro',\n",
    "              'brasileiras', 'brasileiros', 'municípios', 'ministro', 'ministra',\n",
    "              'encontram', 'trata', 'entreguei', 'encontram', 'aconteceram', 'acontecem',\n",
    "              'tocante', 'passado', 'passada', 'agradecer', 'encaminhando', 'encaminhada'\n",
    "              'cumprimento', 'ouvem', 'apelo', 'responsável', 'ninguém', 'pessoa',\n",
    "              'atender', 'receber', 'torno', 'aproximadamente', 'significa', 'casos',\n",
    "              'parabenizo', 'parabenizar', 'parecer', 'novamente', 'registrar', 'registro',\n",
    "              'comemoramos', 'últimos', 'passa', 'dissermos', 'gostaríamos', 'lembrar',\n",
    "              'passou', 'observado', 'lembrei', 'aproveito', 'manifestar', 'junto',\n",
    "              'tratar', 'pretendo', 'falarei', 'trarei', 'citando', 'sinto', 'cheguei',\n",
    "              'guardo', 'faça', 'constar', 'deixar', 'tomei', 'encaminho', 'mesa',\n",
    "              'ocupo', 'ocupar', 'ocupei', 'subo', 'assomo', 'assumo', 'volto', 'ocupamos',\n",
    "              'prestar', 'solicitação', 'manifestar', 'prestar', 'recebi', 'posse',\n",
    "              'parlamento', 'discurso', 'debate', 'plenário', 'bancada', 'governador',\n",
    "              'prefeito', 'senado', 'nenhum', 'texto', 'matéria', 'evento', 'votação',\n",
    "              'votar', 'voto', 'frente', 'município', 'atuação', 'pegar', 'mesa', 'atestado',\n",
    "              'atendendo', 'apelo', 'significa', 'atender', 'torno', 'aproximadamente'\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_freqwords(text):\n",
    "    \"\"\"custom function to remove the frequent words\"\"\"\n",
    "    return \" \".join([word for word in str(text).split() if word not in freq_words])\n",
    "\n",
    "df[\"tokenized\"] = df[\"tokenized\"].apply(lambda text: remove_freqwords(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>session</th>\n",
       "      <th>phase</th>\n",
       "      <th>discourse_link</th>\n",
       "      <th>speaker</th>\n",
       "      <th>party</th>\n",
       "      <th>coalition</th>\n",
       "      <th>state</th>\n",
       "      <th>region</th>\n",
       "      <th>original_discourse</th>\n",
       "      <th>clean_discourse</th>\n",
       "      <th>tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-01-11</td>\n",
       "      <td>195.2.51.O</td>\n",
       "      <td>short address</td>\n",
       "      <td>https://www.camara.leg.br/internet/SitaqWeb/Te...</td>\n",
       "      <td>nilton capixaba</td>\n",
       "      <td>ptb</td>\n",
       "      <td>opposition</td>\n",
       "      <td>ro</td>\n",
       "      <td>north</td>\n",
       "      <td>O SR. NILTON CAPIXABA (PTB-RO. Pronuncia o seg...</td>\n",
       "      <td>Sr. Presidente, Sras. e Srs. Deputados, na sem...</td>\n",
       "      <td>gabinete câmara diretor ceplac comissão execut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-01-11</td>\n",
       "      <td>195.2.51.O</td>\n",
       "      <td>parliamentarian communications</td>\n",
       "      <td>https://www.camara.leg.br/internet/SitaqWeb/Te...</td>\n",
       "      <td>sérgio novais</td>\n",
       "      <td>psb</td>\n",
       "      <td>opposition</td>\n",
       "      <td>ce</td>\n",
       "      <td>northeast</td>\n",
       "      <td>O SR. SÉRGIO NOVAIS (Bloco/PSB-CE. Como Líder....</td>\n",
       "      <td>Sr. Presidente, Sras. e Srs. Deputados, prime...</td>\n",
       "      <td>solidariedade amapá joão capiberibe psb postur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-01-11</td>\n",
       "      <td>195.2.51.O</td>\n",
       "      <td>short address</td>\n",
       "      <td>https://www.camara.leg.br/internet/SitaqWeb/Te...</td>\n",
       "      <td>marcos afonso</td>\n",
       "      <td>pt</td>\n",
       "      <td>opposition</td>\n",
       "      <td>ac</td>\n",
       "      <td>north</td>\n",
       "      <td>O SR. MARCOS AFONSO (PT-AC. Pronuncia o seguin...</td>\n",
       "      <td>Sr. Presidente, Sras. e Srs. Deputados, venho...</td>\n",
       "      <td>tribuna protesto rede globo televisão veiculou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date     session                           phase  \\\n",
       "0  2000-01-11  195.2.51.O                   short address   \n",
       "1  2000-01-11  195.2.51.O  parliamentarian communications   \n",
       "2  2000-01-11  195.2.51.O                   short address   \n",
       "\n",
       "                                      discourse_link          speaker party  \\\n",
       "0  https://www.camara.leg.br/internet/SitaqWeb/Te...  nilton capixaba   ptb   \n",
       "1  https://www.camara.leg.br/internet/SitaqWeb/Te...    sérgio novais   psb   \n",
       "2  https://www.camara.leg.br/internet/SitaqWeb/Te...    marcos afonso    pt   \n",
       "\n",
       "    coalition state     region  \\\n",
       "0  opposition    ro      north   \n",
       "1  opposition    ce  northeast   \n",
       "2  opposition    ac      north   \n",
       "\n",
       "                                  original_discourse  \\\n",
       "0  O SR. NILTON CAPIXABA (PTB-RO. Pronuncia o seg...   \n",
       "1  O SR. SÉRGIO NOVAIS (Bloco/PSB-CE. Como Líder....   \n",
       "2  O SR. MARCOS AFONSO (PT-AC. Pronuncia o seguin...   \n",
       "\n",
       "                                     clean_discourse  \\\n",
       "0  Sr. Presidente, Sras. e Srs. Deputados, na sem...   \n",
       "1   Sr. Presidente, Sras. e Srs. Deputados, prime...   \n",
       "2   Sr. Presidente, Sras. e Srs. Deputados, venho...   \n",
       "\n",
       "                                           tokenized  \n",
       "0  gabinete câmara diretor ceplac comissão execut...  \n",
       "1  solidariedade amapá joão capiberibe psb postur...  \n",
       "2  tribuna protesto rede globo televisão veiculou...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('amazon_clean_discourses.tsv', sep='\\t', encoding='utf-8', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
